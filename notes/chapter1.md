### 第一章：统计学习方法概述
> 代码文件：最小二乘法（过拟合与正则化） \
> [Chapter1_LeastSquaresMethod.py](./Chapter1_LeastSquaresMethod.py)
#### 统计学习
1. 特点
    - 以计算机及网络为平台
    - 以数据为研究对象
    - 目的是对数据进行预测分析
    - 以方法为中心，构建并应用模型
    - 统计学习是多领域交叉学科，并且有独自的理论体系和方法论
1. 对象
    - 研究对象是数据
    - 基本假设：同类数据具有一定的统计规律性
1. 目的
    - 对数据进行预测与分析
    - 预测、推荐
1. 方法
    - 三要素：模型 (model)、策略 (strategy)、算法 (algorithm)
1. 步骤
    - 得到一个有限的数据集合
    - 确定可能的假设空间 (hypothesis space)
    - 确定学习的策略
    - 确定求解的算法
    - 选择最优的模型
    - 预测与分析
1. 重要性
    - 处理海量数据
    - 计算机智能化
    - 推动计算机科学的发展
> 一般认为计算机科学由三维组成：系统、计算和信息。
> 统计学习属于 `信息` 这一维，并在其中起着核心作用
#### 监督学习
1. 基本概念
    - 输入空间: 所有输入数据的集合
    - 输出空间: 所有输出数据的集合
    - 特征空间: 所有特征向量存在的空间
    > 有时候特征空间和输入空间是同一空间，不与区分
    - 联合概率分布: `X` 和 `Y` 具有联合概率分布的假设就是监督学习对于数据的基本假设
    - 假设空间: 输入空间到输出空间的映射的集合
1. 问题形式化
    - 监督学习利用给定数据集学习一个模型，再用模型对测试样本进行预测
    - 训练数据是人工给出的带有 `Label` 的数据
    - 整个过程分为学习和预测两个过程
#### 统计学习三要素
`方法 = 模型 + 策略 + 算法`
1. 模型
    - 模型就是要学习的条件概率分布或者决策函数
1. 策略
    - 策略实际上就是学习或者选择最优模型的准测
    - 损失函数
      - 0-1损失函数: $L(Y,f(X)) = D(x) = \begin{cases}1,& \text(Y \neq f(X)); 0,& \text(Y = f(X).\end{cases}$
      - 平方损失函数: $L(Y,f(X)) = (Y - f(X))^2$
      - 绝对损失函数: $L(Y,f(X)) = |Y - f(X)|$
      - 对数损失函数: $L(Y,f(X)) = -log P(Y|X)$
    - 经验风险最小化 (ERM) 策略认为经验风险最小的模型就是最优的模型
    - 结构风险最小化 (SRM) 等价于正则化 (regularization)，认为结构风险最小的模型就是最优的模型
1. 算法
    - 算法指学习模型的具体计算方法
    
